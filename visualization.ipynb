{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "\n",
    "input_file = 'hebrew_dict/hebrew_verbs.csv'\n",
    "\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# filter by roots, binyan, and part of speech\n",
    "binyans = [\"pa'al\", \"nif'al\", \"pi'el\", \"hif'il\", \"hitpa'el\"]\n",
    "edge_categories = [\"permutation\", \"semantic\", \"levenshtein-1\"]\n",
    "binyan = binyans[0]\n",
    "edge_category = edge_categories[2]\n",
    "\n",
    "df['Root'] = df['Root'].apply(ast.literal_eval)\n",
    "df = df[df['Binyan'].apply(lambda x: x == binyan)]\n",
    "df = df[df['Part of speech'].apply(lambda x: x == \"Verb\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_final_form(hebrew_chars):\n",
    "    # Define mapping of normal form characters to their final forms\n",
    "    # reversed due to hebrew direction\n",
    "    final_form_mapping = {\n",
    "        \"ץ\": \"צ\",\n",
    "        \"ף\": \"פ\",\n",
    "        \"ן\": \"נ\",\n",
    "        \"ם\": \"מ\",\n",
    "        \"ך\": \"כ\"\n",
    "    }\n",
    "\n",
    "    # Replace final forms in the list\n",
    "    return ''.join([final_form_mapping.get(char, char) for char in hebrew_chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "node_counter_dict = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    root = ''.join(row['Root'])\n",
    "    word = row['Word (he)']\n",
    "    meaning = row['Meaning']\n",
    "\n",
    "    G.add_node(root, title=meaning, word=word)\n",
    "    # node_counter_dict[root] = Counter(replace_final_form(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.autonotebook import tqdm\n",
    "from Levenshtein import distance\n",
    "\n",
    "def edge_levenshtein_k(n, m, k):\n",
    "    return distance(replace_final_form(n), replace_final_form(m)) <= k\n",
    "\n",
    "def is_permutation(n, m):\n",
    "    return node_counter_dict[n] == node_counter_dict[m]\n",
    "\n",
    "def add_perm_edges():\n",
    "    for n, m in itertools.combinations(G.nodes(), 2):\n",
    "        if is_permutation(n, m):  # edge_levenshtein_k(n, m, 1):\n",
    "            G.add_edge(n, m)\n",
    "\n",
    "G.remove_edges_from(list(G.edges))\n",
    "# Compute embeddings for each node's semantic meaning\n",
    "node_embeddings = {}\n",
    "total_nodes = len(G)\n",
    "\n",
    "def compute_embeddings():\n",
    "    # Load a pre-trained model\n",
    "    model = SentenceTransformer(\"paraphrase-multilingual-mpnet-base-v2\")\n",
    "    with tqdm(total=total_nodes, desc=\"Computing Embeddings\") as pbar:\n",
    "        for node, data in G.nodes(data=True):\n",
    "            semantic_meaning = data.get(\"title\", \"\")\n",
    "            embeddings = model.encode(semantic_meaning, convert_to_tensor=True)\n",
    "            node_embeddings[node] = embeddings\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = binyan\n",
    "\n",
    "def dump_semantic_cache(edges_similarity):\n",
    "    node_embeddings_json = {node: emb.tolist() for node, emb in node_embeddings.items()}\n",
    "\n",
    "    with open(f\"graphs_raw/semantic/semantic_cache/{output_fname}.json\", \"w\") as outfile:\n",
    "        json.dump({\"node_embeddings\": node_embeddings_json, \"edges_similarity\": edges_similarity}, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "def load_semantic_cache():\n",
    "    # Load node embeddings from the JSON file\n",
    "    with open(f\"graphs_raw/semantic/semantic_cache/{output_fname}.json\", \"r\") as f:\n",
    "        semantic_cached = json.load(f)\n",
    "        loaded_node_embeddings, loaded_edge_semantic_similarity = semantic_cached[\"node_embeddings\"], semantic_cached[\"edges_similarity\"]\n",
    "        # Convert loaded embeddings back to tensors\n",
    "        # node_embeddings = {node: torch.tensor(emb) for node, emb in loaded_node_embeddings.items()}\n",
    "        edges_similarity = {ast.literal_eval(nodes) : val for nodes, val in loaded_edge_semantic_similarity.items()}\n",
    "        return edges_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_threshold = 0.7\n",
    "\n",
    "def similarity_to_weight(similarity, similarity_threshold, min_weight, max_weight):\n",
    "    if similarity >= similarity_threshold:\n",
    "        weight = min_weight + (max_weight - min_weight) * ((similarity - similarity_threshold) / (1 - similarity_threshold))\n",
    "    else:\n",
    "        weight = min_weight\n",
    "    return round(weight, 1)\n",
    "\n",
    "def add_semantic_edges():\n",
    "    G.remove_edges_from(list(G.edges))\n",
    "    cur_combinations = list(itertools.combinations(G.nodes(), 2))\n",
    "    edges_similarity = load_semantic_cache()\n",
    "    with tqdm(total=len(cur_combinations), desc=\"Adding semantic edges\") as pbar:\n",
    "        for n, m in cur_combinations:\n",
    "            similarity = edges_similarity.get((n , m), edges_similarity.get((m, n), 0))\n",
    "            if similarity > semantic_threshold:\n",
    "                G.add_edge(n, m, weight=similarity_to_weight(similarity, semantic_threshold, 0.4, 11))\n",
    "            pbar.update(1)\n",
    "\n",
    "def add_levenshtein_edges():\n",
    "    for n, m in tqdm(itertools.combinations(G.nodes(), 2)):\n",
    "        if edge_levenshtein_k(n, m, 1):\n",
    "            G.add_edge(n, m)\n",
    "\n",
    "add_levenshtein_edges()\n",
    "# print(nx.get_edge_attributes(G, 'weight'))\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize nodes by degree\n",
    "weighted_degrees = dict(G.degree(weight='weight'))\n",
    "\n",
    "def scale_weights(w, min_weight, max_weight):\n",
    "    scaled_weight = min_weight + (max_weight - min_weight) * ((w - min_weight) / (max_weight - min_weight))\n",
    "    return max(min_weight, scaled_weight)\n",
    "\n",
    "node_sizes = {node: scale_weights(weighted_degrees[node], 8, 36) for node in G.nodes()}\n",
    "nx.set_node_attributes(G, node_sizes, \"size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, f\"graphs_raw/{edge_category}/{output_fname}.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "# Create a new pyvis network\n",
    "net = Network(notebook=True, bgcolor=\"#222222\",\n",
    "              font_color=\"white\", height=\"100vh\")\n",
    "\n",
    "# filter degree\n",
    "nonzero_degree_nodes = [node for node, degree in G.degree if degree != 0]\n",
    "\n",
    "# Create a new graph with only nodes of nonzero degree\n",
    "G = G.subgraph(nonzero_degree_nodes)\n",
    "net.from_nx(G)\n",
    "\n",
    "physics = False\n",
    "# Disable physics for a static layout\n",
    "net.force_atlas_2based = physics\n",
    "if physics:\n",
    "    net.repulsion = 1000\n",
    "# Set physics to False to create a static layout\n",
    "net.options = {\n",
    "    \"nodes\": {\n",
    "        \"font\": {\n",
    "            \"size\": 36,\n",
    "            \"face\": \"tahoma\"\n",
    "        },\n",
    "        \"shape\": \"dot\",\n",
    "        \"size\": 10,\n",
    "        \"color\": {\n",
    "            \"border\": \"#2B7CE9\",\n",
    "            \"background\": \"#666\",\n",
    "            \"highlight\": {\n",
    "                \"border\": \"#2B7CE9\",\n",
    "                \"background\": \"#848484\"\n",
    "            }\n",
    "        },\n",
    "        \"shadow\": {\n",
    "            \"enabled\": True,\n",
    "            \"size\": 15\n",
    "        },\n",
    "        \"title\": \"meaning\"  # Hover attribute to display semantic meaning\n",
    "    },\n",
    "    \"edges\": {\n",
    "        \"color\": {\n",
    "            \"color\": \"#ccc\",\n",
    "            \"highlight\": \"#848484\"\n",
    "        }\n",
    "    },\n",
    "    \"interaction\": {\n",
    "        \"hover\": True,\n",
    "        \"navigationButtons\": True,\n",
    "        \"zoomView\": True,\n",
    "        \"dragView\": physics\n",
    "    },\n",
    "    \"physics\": {\n",
    "        \"enabled\": physics\n",
    "    },\n",
    "    \"layout\": ({\n",
    "        \"hierarchical\": {\n",
    "            \"enabled\": True,\n",
    "            \"levelSeparation\": 250,  # Adjust separation between levels\n",
    "            \"nodeSpacing\": 300,\n",
    "            \"treeSpacing\": 200,\n",
    "            \"direction\": \"UD\",\n",
    "            \"sortMethod\": \"directed\"\n",
    "        }\n",
    "    } if not physics else {})\n",
    "}\n",
    "\n",
    "# Show the network\n",
    "net.show(f\"html/graphs/{edge_category}/{output_fname}.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
